{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\joant\\OneDrive\\Stucom\\MasterIA\\BigData\\Projecte3_Meteorologia\\Datos_Proyecto\"\n",
    "\n",
    "df_observations = pd.read_csv(r\"C:\\Users\\joant\\OneDrive\\Stucom\\MasterIA\\BigData\\Projecte3_Meteorologia\\Datos_Proyecto\\observations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHECK FOR NA VALUES ON DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in os.listdir(path):\n",
    "    df = pd.read_csv(os.path.join(path, csv)) \n",
    "    print(f\"{csv}:\\n{df.isna().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZACION DE VALORES NULOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Resumen de los datos nulos\n",
    "print(\"Resumen de valores nulos por columna:\")\n",
    "print(df_observations.isnull().sum())\n",
    "\n",
    "# 3. Total de nulos\n",
    "total_nulos = df_observations.isnull().sum().sum()\n",
    "print(f\"\\nTotal de valores nulos en el DataFrame: {total_nulos}\")\n",
    "\n",
    "# 4. Porcentaje de datos nulos por columna\n",
    "porcentaje_nulos = (df_observations.isnull().sum() / len(df_observations)) * 100\n",
    "print(\"\\nPorcentaje de valores nulos por columna:\")\n",
    "print(porcentaje_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la cantidad de valores nulos por columna\n",
    "null_counts = df_observations.isnull().sum()\n",
    "\n",
    "# Calcular el total de registros por columna\n",
    "total_counts = df_observations.shape[0]\n",
    "\n",
    "# Crear una nueva DataFrame con los datos para graficar\n",
    "data = pd.DataFrame({\n",
    "    'No Nulos': total_counts - null_counts.values,\n",
    "    'Nulos': null_counts.values\n",
    "}, index=null_counts.index)\n",
    "\n",
    "# Configurar el tamaño de la figura\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Crear el gráfico de barras apiladas (gráfico de columnas agrupadas)\n",
    "data.plot(kind='bar', stacked=False, color=['green', 'red'])\n",
    "\n",
    "# Títulos y etiquetas\n",
    "plt.title(\"Total de Registros vs Valores Nulos por Columna\")\n",
    "plt.xlabel(\"Columnas\")\n",
    "plt.ylabel(\"Cantidad de Registros\")\n",
    "plt.xticks(rotation=90)  # Rotar las etiquetas del eje x si es necesario\n",
    "\n",
    "# Agregar leyenda\n",
    "plt.legend([\"No Nulos\", \"Nulos\"])\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de las columnas con nulos\n",
    "cols_nulos = ['precipitation', 'temp_max', 'temp_min', 'wind']\n",
    "print(df_observations[cols_nulos].describe())\n",
    "\n",
    "# Histograma de cada columna\n",
    "for col in cols_nulos:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df_observations[col], kde=True, bins=30, color='blue')\n",
    "    plt.title(f\"Distribución de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANALISIS DE DATOS CON NULOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"E:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\observations.csv\")\n",
    "\n",
    "data_cleaned = data.dropna()\n",
    "\n",
    "numerical_data = data_cleaned.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Mapa de Calor de Correlaciones')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VISUALIZAR LOS DATOS QUE RESALTAN EN EL GRÁFICO DE CORRELACIONES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEATHER_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot de weather_id vs precipitación\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='weather_id', y='precipitation', hue='weather_id', data=data_cleaned, palette='Blues', legend=False)\n",
    "plt.title('Distribución de Precipitación según Weather ID')\n",
    "plt.xlabel('Weather ID')\n",
    "plt.ylabel('Precipitación')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot de weather_id vs viento\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='weather_id', y='wind', data=data_cleaned, palette='Greens')\n",
    "plt.title('Distribución de Viento según Weather ID')\n",
    "plt.xlabel('Weather ID')\n",
    "plt.ylabel('Viento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot de weather_id vs viento\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='cloudiness_id', y='solar_radiation', data=data_cleaned, palette='Reds')\n",
    "plt.title('Distribución de Radiación Solar según Cloudiness ID')\n",
    "plt.xlabel('Cloudiness ID')\n",
    "plt.ylabel('Radiación Solar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METODOS DE IMPUTACIÓN DE VALORES NULOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con los valores previos y posteriores del valor nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"E:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\observations.csv\")\n",
    "dates = pd.read_csv(r\"E:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\dates.csv\")  # Archivo con las fechas\n",
    "\n",
    "# Unir la fecha al DataFrame principal\n",
    "df = df.merge(dates, on='date_id', how='left')\n",
    "\n",
    "# Convertir la fecha a formato datetime y extrae\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# ordenar por 'date'\n",
    "df = df.sort_values(by='date')\n",
    "\n",
    "# Calcular las medias por estación y año para las columnas con valores nulos\n",
    "columns_to_impute = ['precipitation', 'temp_max', 'temp_min', 'wind']\n",
    "\n",
    "for col in columns_to_impute:\n",
    "    df[col] = df[col].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "df.to_csv(r\"E:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\observations_full.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANALISIS DE DATOS SIN NULOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(r\"C:\\Users\\joant\\OneDrive\\Stucom\\MasterIA\\BigData\\Projecte3_Meteorologia\\Datos_Proyecto\\observations_full.csv\")\n",
    "\n",
    "numerical_data = full_data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Mapa de Calor de Correlaciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de las columnas que contenian nulos\n",
    "cols_nulos = ['precipitation', 'temp_max', 'temp_min', 'wind']\n",
    "print(full_data[cols_nulos].describe())\n",
    "\n",
    "# Histograma de cada columna\n",
    "for col in cols_nulos:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(full_data[col], kde=True, bins=30, color='blue')\n",
    "    plt.title(f\"Distribución de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VISUALIZAR LOS DATOS QUE RESALTAN EN EL GRÁFICO DE CORRELACIONES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEATHER ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot de weather_id vs precipitación\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='weather_id', y='precipitation', hue='weather_id', data=full_data, palette='Blues', legend=False)\n",
    "plt.title('Distribución de Precipitación según Weather ID')\n",
    "plt.xlabel('Weather ID')\n",
    "plt.ylabel('Precipitación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRECIPITATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot de weather_id vs viento\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='weather_id', y='wind', data=full_data, palette='Greens')\n",
    "plt.title('Distribución de Viento según Weather ID')\n",
    "plt.xlabel('Weather ID')\n",
    "plt.ylabel('Viento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEATHER ID vs WIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot de weather_id vs viento\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='cloudiness_id', y='solar_radiation', data=full_data, palette='Reds')\n",
    "plt.title('Distribución de Radiación Solar según Cloudiness ID')\n",
    "plt.xlabel('Cloudiness ID')\n",
    "plt.ylabel('Radiación Solar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARGAR LOS DATOS SQL Y CREAR LOS GRAFICOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(r\"C:\\Users\\joant\\OneDrive\\Stucom\\MasterIA\\BigData\\Projecte3_Meteorologia\\Entregables\\Code\\weather.db\")\n",
    "\n",
    "# Cargar cada tabla en un DataFrame de pandas\n",
    "df_cloudiness = pd.read_sql_query(\"SELECT * FROM cloudiness\", conn)\n",
    "df_dates = pd.read_sql_query(\"SELECT * FROM dates\", conn)\n",
    "df_observations = pd.read_sql_query(\"SELECT * FROM observations_full\", conn)\n",
    "df_weather = pd.read_sql_query(\"SELECT * FROM weather\", conn)\n",
    "df_seasons = pd.read_sql_query(\"SELECT * FROM seasons\", conn)\n",
    "\n",
    "# Cerrar la conexión cuando hayas terminado\n",
    "conn.close()\n",
    "\n",
    "# Unir las tablas usando merge\n",
    "df = df_observations \\\n",
    "    .merge(df_dates, on='date_id') \\\n",
    "    .merge(df_weather, on='weather_id') \\\n",
    "    .merge(df_cloudiness, on='cloudiness_id') \\\n",
    "    .merge(df_seasons, on='estacion_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISTRIBUCIÓN DE LAS TEMPERATURAS MAXIMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar un histograma de temperatura máxima\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['temp_max'].dropna(), bins=30, kde=True)\n",
    "plt.title(\"Distribución de Temperatura Máxima\")\n",
    "plt.xlabel(\"Temperatura Máxima (°C)\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEMPERATURA MAX/MIN POR FECHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna de fechas a tipo datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Graficar temperatura máxima y mínima a lo largo del tiempo\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.lineplot(x='date', y='temp_max', data=df, label='Temp Max')\n",
    "sns.lineplot(x='date', y='temp_min', data=df, label='Temp Min')\n",
    "plt.title(\"Temperatura Máxima y Mínima a lo Largo del Tiempo\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Temperatura (°C)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HUMEDAD POR CONDICION CLIMATICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la humedad promedio por tipo de clima\n",
    "df_weather_humidity = df.groupby('weather')['humidity'].mean().reset_index()\n",
    "\n",
    "# Graficar la humedad promedio por tipo de clima\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='humidity', y='weather', hue='weather', data=df_weather_humidity, palette=\"viridis\", legend=False)\n",
    "plt.title(\"Humedad Promedio por Condición Climática\")\n",
    "plt.xlabel(\"Humedad (%)\")\n",
    "plt.ylabel(\"Condición Climática\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEMPERATURA MÁXIMA POR TIPO DE TIEMPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='weather', y='temp_max', hue='weather', data=df, palette=\"Set3\", legend=False)\n",
    "plt.title(\"Distribución de Temperatura Máxima por Condición Climática\")\n",
    "plt.xlabel(\"Condición Climática\")\n",
    "plt.ylabel(\"Temperatura Máxima (°C)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIENTO vs PRESIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='wind', y='pressure', hue='cloudiness', data=df, palette=\"bright\")\n",
    "plt.title(\"Viento vs. Presión según Nubosidad\")\n",
    "plt.xlabel(\"Velocidad del Viento (m/s)\")\n",
    "plt.ylabel(\"Presión (hPa)\")\n",
    "plt.legend(title=\"Nubosidad\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRECIPITACION POR VIENTO Y TIPO DE TIEMPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='wind', y='precipitation', hue='weather', data=df, palette=\"Set2\", s=50)\n",
    "plt.title(\"Precipitación vs. Viento por Weather\")\n",
    "plt.xlabel(\"Velocidad del Viento (m/s)\")\n",
    "plt.ylabel(\"Precipitación (mm)\")\n",
    "plt.legend(title='Tipo de Tiempo', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRECIPITACIÓN POR TIPO DE TIEMPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='weather', y='precipitation', hue='weather', data=df, palette=\"viridis\", legend=False)\n",
    "plt.title(\"Precipitación Promedio por Weather\")\n",
    "plt.xlabel(\"Tipo de Tiempo\")\n",
    "plt.ylabel(\"Precipitación Promedio (mm)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEMPERATURA PROMEDIO POR MES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTIR date A datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# EXTRAER MES Y AÑO\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# AGRUPAR POR MES Y CALCULAR LA TEMPERATURA PROMEDIO\n",
    "df_temp_by_month = df.groupby('month').agg({'temp_max': 'mean', 'temp_min': 'mean'}).reset_index()\n",
    "\n",
    "# MOSTRAR GRAFICO\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df_temp_by_month, x='month', y='temp_max', marker='o', label='Temp Max', color='red')\n",
    "sns.lineplot(data=df_temp_by_month, x='month', y='temp_min', marker='o', label='Temp Min', color='blue')\n",
    "plt.title(\"Temperatura Promedio por Mes\")\n",
    "plt.xlabel(\"Mes\")\n",
    "plt.ylabel(\"Temperatura (°C)\")\n",
    "plt.xticks(ticks=df_temp_by_month['month'], labels=[\"Ene\", \"Feb\", \"Mar\", \"Abr\", \"May\", \"Jun\", \"Jul\", \"Ago\", \"Sep\", \"Oct\", \"Nov\", \"Dic\"])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEMPERATURA PROMEDIO POR AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTIR date A datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# EXTRAER MES Y AÑO\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# AGRUPAR POR MES Y CALCULAR LA TEMPERATURA PROMEDIO\n",
    "df_temp_by_month = df.groupby('year').agg({'temp_max': 'mean', 'temp_min': 'mean'}).reset_index()\n",
    "\n",
    "# MOSTRAR GRAFICO\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df_temp_by_month, x='year', y='temp_max', marker='o', label='Temp Max', color='red')\n",
    "sns.lineplot(data=df_temp_by_month, x='year', y='temp_min', marker='o', label='Temp Min', color='blue')\n",
    "plt.title(\"Temperatura Promedio por Año\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Temperatura (°C)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VARIABILIDAD DE LA VISIBILIDAD POR CONDICIÓN CLIMÁTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafica de la visibilidad por condición climática\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df, x='weather', y='visibility', hue='weather_id', palette=\"viridis\", legend=False)\n",
    "plt.title('Variabilidad de la Visibilidad por Condición Climática')\n",
    "plt.xlabel('Condición Climática')\n",
    "plt.ylabel('Visibilidad')\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEMPERATURA MÁXIMA Y MÍNIMA PROMEDIO POR ESTACIÓN DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperatura promedio por estación\n",
    "temp_seasonal_avg = df.groupby('estacion')[['temp_max', 'temp_min']].mean()\n",
    "\n",
    "# Gráfica de barras para temperatura máxima y mínima por estación\n",
    "plt.figure(figsize=(10, 6))\n",
    "temp_seasonal_avg.plot(kind='bar', color=['#ff8f1e','#47bfff'])\n",
    "plt.title('Temperatura Máxima y Mínima Promedio por Estación del Año')\n",
    "plt.xlabel('Estación')\n",
    "plt.xticks(ticks=range(4), labels=['Invierno', 'Primavera', 'Verano', 'Otoño'], rotation=0)\n",
    "plt.ylabel('Temperatura Promedio')\n",
    "plt.legend(['Temp Max', 'Temp Min'])\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.api import VAR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\joant\\OneDrive\\Stucom\\MasterIA\\BigData\\Projecte3_Meteorologia\\Datos_Proyecto\\observations_full.csv')\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df.set_index('date',inplace=True)\n",
    "\n",
    "df = df.asfreq('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import concurrent.futures\n",
    "\n",
    "# Lista de variables para las que queremos hacer predicciones\n",
    "variables = ['precipitation', 'temp_max', 'temp_min', 'wind', 'humidity', 'pressure', 'solar_radiation', 'visibility', 'weather_id', 'cloudiness_id']\n",
    "\n",
    "# Ruta donde se guardarán los modelos entrenados\n",
    "models_path = \"sarima_models\"\n",
    "os.makedirs(models_path, exist_ok=True)  # Crear el directorio si no existe\n",
    "\n",
    "# Función para ajustar y guardar el modelo si no existe, o cargarlo si ya está guardado\n",
    "def fit_or_load_model(variable_name):\n",
    "    model_filename = os.path.join(models_path, f\"{variable_name}_sarima.pkl\")\n",
    "    \n",
    "    if os.path.exists(model_filename):\n",
    "        # Si el modelo ya existe, cargarlo\n",
    "        sarima_model = joblib.load(model_filename)\n",
    "        print(f\"Modelo SARIMA para {variable_name} cargado desde {model_filename}\")\n",
    "    else:\n",
    "        # Si el modelo no existe, ajustarlo y guardarlo\n",
    "        model = SARIMAX(df[variable_name],\n",
    "                        order=(1, 1, 1),\n",
    "                        seasonal_order=(1, 1, 1, 12),\n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False)\n",
    "        \n",
    "        sarima_model = model.fit(disp=False, method='powell')\n",
    "        joblib.dump(sarima_model, model_filename, compress=4)\n",
    "        print(f\"Modelo SARIMA para {variable_name} ajustado y guardado en {model_filename}\")\n",
    "    \n",
    "    return sarima_model\n",
    "\n",
    "# Función para hacer predicciones usando un modelo ajustado o cargado\n",
    "def forecast_with_model(variable_name):\n",
    "    sarima_model = fit_or_load_model(variable_name)\n",
    "    forecast = sarima_model.get_forecast(steps=31)\n",
    "    forecast_mean = forecast.predicted_mean\n",
    "    return forecast_mean\n",
    "\n",
    "# Ejecutar las predicciones en paralelo usando ThreadPoolExecutor\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    forecasts = list(executor.map(forecast_with_model, variables))\n",
    "\n",
    "# Almacenar los resultados en un DataFrame para facilidad de visualización\n",
    "predictions_df = pd.DataFrame({variables[i]: forecasts[i] for i in range(len(variables))})\n",
    "\n",
    "predictions_df.to_csv(r'C:\\Users\\joant\\OneDrive\\Stucom\\MasterIA\\BigData\\Projecte3_Meteorologia\\Entregables\\Code\\predictions.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\observations_full.csv\")\n",
    "\n",
    "# Extract time-based features\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "# Drop the original date column\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# Select features and targets\n",
    "features = ['precipitation', 'temp_max','temp_min', 'wind', 'humidity', 'pressure', \n",
    "            'solar_radiation', 'visibility', 'weather_id', 'estacion_id', 'cloudiness_id', \n",
    "            'year', 'month', 'day']\n",
    "\n",
    "targets = ['precipitation', 'temp_max','temp_min', 'wind', 'humidity', 'pressure']\n",
    "\n",
    "for target in targets:\n",
    "\n",
    "    features_clean = [feature for feature in features if feature != target]\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df[features_clean]\n",
    "    y = df[target]\n",
    "\n",
    "    # Split data into train and test sets (using time-based split for time series)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Train a Random Forest model for prediction\n",
    "    model = RandomForestRegressor(n_estimators=300, max_depth=15, min_samples_split=5, min_samples_leaf=4, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    print(f\"\\nModelo {target}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "    # Save the model using joblib\n",
    "    model_path = fr'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\SVM\\features_prediction\\{target}_rfr_model.pkl'\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "    print(f\"Modelo {target} guardado en: {model_path} (intro)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROPHET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar el modelo y hacer predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from plotly import graph_objs as go\n",
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly\n",
    "\n",
    "df = pd.read_csv(r'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\observations_full.csv')\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=df['date'], y=df['humidity'], name='humidity',line_color='red'))\n",
    "# fig.layout.update(title_text='Time Series data with Rangeslider',xaxis_rangeslider_visible=True)\n",
    "# fig.show()\n",
    "\n",
    "targets = ['precipitation','temp_max','temp_min','wind','humidity','pressure','solar_radiation','visibility','cloudiness_id']\n",
    "\n",
    "for target in targets:\n",
    "\n",
    "    X = df[['date',target]]\n",
    "    y = df[target]\n",
    "\n",
    "    train_df = pd.DataFrame()\n",
    "    train_df['ds'] = pd.to_datetime(X['date'])\n",
    "    train_df['y']=y\n",
    "    train_df.head(2)\n",
    "\n",
    "    model = Prophet()\n",
    "    model.fit(train_df)\n",
    "    joblib.dump(model,fr\"D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\Prophet\\models\\prophet_{target}.pkl\")\n",
    "\n",
    "\n",
    "    future = model.make_future_dataframe(periods=365)\n",
    "    forecast = model.predict(future)\n",
    "    forecast.to_csv(fr\"D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\Prophet\\Predictions_2025\\predictions_{target}.csv\")\n",
    "\n",
    "    # fig1 = plot_plotly(model, forecast)\n",
    "    # fig1.show()\n",
    "\n",
    "    # #plot component wise forecast\n",
    "    # fig2 = model.plot_components(forecast)\n",
    "    # fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Mejores parámetros para el modelo precipitation: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 500, 'subsample': 0.7}\n",
      "\n",
      "Modelo precipitation - XGBoost (Con mejores parámetros)\n",
      "Mean Absolute Error (MAE): 13.942166633159891\n",
      "Root Mean Squared Error (RMSE): 16.305101710767545\n",
      "Modelo precipitation guardado en: D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\XGBoost\\precipitation_xgb_model_best.pkl (XGB - Mejores parámetros)\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Mejores parámetros para el modelo temp_max: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 500, 'subsample': 0.7}\n",
      "\n",
      "Modelo temp_max - XGBoost (Con mejores parámetros)\n",
      "Mean Absolute Error (MAE): 9.217679092750755\n",
      "Root Mean Squared Error (RMSE): 10.911769981897358\n",
      "Modelo temp_max guardado en: D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\XGBoost\\temp_max_xgb_model_best.pkl (XGB - Mejores parámetros)\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Mejores parámetros para el modelo temp_min: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 500, 'subsample': 0.7}\n",
      "\n",
      "Modelo temp_min - XGBoost (Con mejores parámetros)\n",
      "Mean Absolute Error (MAE): 5.628657760378596\n",
      "Root Mean Squared Error (RMSE): 6.666075949489911\n",
      "Modelo temp_min guardado en: D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\XGBoost\\temp_min_xgb_model_best.pkl (XGB - Mejores parámetros)\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Mejores parámetros para el modelo wind: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 500, 'subsample': 0.7}\n",
      "\n",
      "Modelo wind - XGBoost (Con mejores parámetros)\n",
      "Mean Absolute Error (MAE): 2.245556171481895\n",
      "Root Mean Squared Error (RMSE): 2.6182469116851443\n",
      "Modelo wind guardado en: D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\XGBoost\\wind_xgb_model_best.pkl (XGB - Mejores parámetros)\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Mejores parámetros para el modelo humidity: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 500, 'subsample': 0.7}\n",
      "\n",
      "Modelo humidity - XGBoost (Con mejores parámetros)\n",
      "Mean Absolute Error (MAE): 18.005973466037037\n",
      "Root Mean Squared Error (RMSE): 20.908215777202923\n",
      "Modelo humidity guardado en: D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\XGBoost\\humidity_xgb_model_best.pkl (XGB - Mejores parámetros)\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Mejores parámetros para el modelo pressure: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 500, 'subsample': 0.7}\n",
      "\n",
      "Modelo pressure - XGBoost (Con mejores parámetros)\n",
      "Mean Absolute Error (MAE): 17.67102269387475\n",
      "Root Mean Squared Error (RMSE): 20.631988185473674\n",
      "Modelo pressure guardado en: D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\XGBoost\\pressure_xgb_model_best.pkl (XGB - Mejores parámetros)\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Mejores parámetros para el modelo solar_radiation: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 500, 'subsample': 0.7}\n",
      "\n",
      "Modelo solar_radiation - XGBoost (Con mejores parámetros)\n",
      "Mean Absolute Error (MAE): 305.4984782868001\n",
      "Root Mean Squared Error (RMSE): 356.7232072523749\n",
      "Modelo solar_radiation guardado en: D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\XGBoost\\solar_radiation_xgb_model_best.pkl (XGB - Mejores parámetros)\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Mejores parámetros para el modelo visibility: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 500, 'subsample': 0.7}\n",
      "\n",
      "Modelo visibility - XGBoost (Con mejores parámetros)\n",
      "Mean Absolute Error (MAE): 5.077807465322998\n",
      "Root Mean Squared Error (RMSE): 5.935506294416025\n",
      "Modelo visibility guardado en: D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\XGBoost\\visibility_xgb_model_best.pkl (XGB - Mejores parámetros)\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Mejores parámetros para el modelo cloudiness_id: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 50, 'min_child_weight': 5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "\n",
      "Modelo cloudiness_id - XGBoost (Con mejores parámetros)\n",
      "Mean Absolute Error (MAE): 0.521740554523468\n",
      "Root Mean Squared Error (RMSE): 0.5998515577265239\n",
      "Modelo cloudiness_id guardado en: D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\XGBoost\\cloudiness_id_xgb_model_best.pkl (XGB - Mejores parámetros)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\observations_full.csv\")\n",
    "\n",
    "# Extract time-based features\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "# Drop the original date column\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# Select features and targets\n",
    "features = ['year', 'month', 'day']\n",
    "X = df[features]\n",
    "\n",
    "targets = ['precipitation', 'temp_max','temp_min', 'wind', 'humidity', 'pressure','solar_radiation','visibility','cloudiness_id']\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000],\n",
    "    'max_depth': [10, 20, 50],\n",
    "    'min_child_weight': [5, 8],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'colsample_bytree': [0.9, 1.0]\n",
    "}\n",
    "\n",
    "for target in targets:\n",
    "    # Separate features and target\n",
    "    y = df[target]\n",
    "\n",
    "    # Split data into train and test sets (using time-based split for time series)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Initialize XGBoost model\n",
    "    model_xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV to find the best hyperparameters\n",
    "    grid_search = GridSearchCV(estimator=model_xgb, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Fit the grid search model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters from the grid search\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"\\nMejores parámetros para el modelo {target}: {best_params}\")\n",
    "\n",
    "    # Refit the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best model on the test data\n",
    "    y_pred_xgb = best_model.predict(X_test)\n",
    "    mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "    rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "    print(f\"\\nModelo {target} - XGBoost (Con mejores parámetros)\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae_xgb}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse_xgb}\")\n",
    "\n",
    "    # Save the best XGBoost model\n",
    "    model_xgb_path = fr'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\XGBoost\\{target}_xgb_model_best.pkl'\n",
    "    joblib.dump(best_model, model_xgb_path)\n",
    "    print(f\"Modelo {target} guardado en: {model_xgb_path} (XGB - Mejores parámetros)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntar las predicciones de todos los targets en un solo data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re\n",
    "import pandas as pd\n",
    "\n",
    "df_predictions = pd.DataFrame()\n",
    "\n",
    "path = r'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\Prophet\\Predictions_2025'\n",
    "\n",
    "_, _, files = next(os.walk(path))\n",
    "    \n",
    "for file in files:\n",
    "\n",
    "    df = pd.read_csv(os.path.join(path,file))\n",
    "\n",
    "    if 'cloudiness' in file:\n",
    "        df['yhat'] = df['yhat'].round(0).astype(int)\n",
    "\n",
    "    \n",
    "    df_predictions[re.search(r'predictions_(.*?).csv', file).group(1)] = df['yhat']\n",
    "\n",
    "df_predictions.insert(0,'date',df['ds'])\n",
    "\n",
    "df_predictions = df_predictions.drop(df_predictions.index[:25000]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_predictions.to_csv(r'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\predictions\\predictions_Prophet.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO weather_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\observations_full.csv')\n",
    "\n",
    "# Process date and add additional time-based features\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['year'] = data['date'].dt.year\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day'] = data['date'].dt.day\n",
    "\n",
    "# Select features and target\n",
    "features = ['year', 'month', 'day', 'precipitation', 'temp_max', 'temp_min', 'wind', 'humidity', 'pressure', 'solar_radiation', 'visibility', 'cloudiness_id']\n",
    "target = 'weather_id'\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# model = SVC(kernel='rbf', C=0.1, gamma='auto', class_weight='balanced', probability=True) Model 3\n",
    "model = SVC(kernel='rbf', C=0.1, gamma='auto', probability=True) # Model 4\n",
    "\n",
    "\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ROC AUC (for multi-class)\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_scaled), multi_class='ovr')\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, r'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\SVM\\weather_id_svm_model_v4.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\observations_full.csv')\n",
    "\n",
    "# Process date and add additional time-based features\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['year'] = data['date'].dt.year\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day'] = data['date'].dt.day\n",
    "\n",
    "# Select features and target\n",
    "features = ['year', 'month', 'day', 'precipitation', 'temp_max', 'temp_min', 'wind', 'humidity', 'pressure', 'solar_radiation', 'visibility', 'cloudiness_id']\n",
    "target = 'weather_id'\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# RANDOM FOREST\n",
    "\n",
    "model_rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "model_rf.fit(X_train_res, y_train_res)\n",
    "y_pred_rf = model_rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Random Forest Classifier - Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "joblib.dump(model_rf,r'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\RandomForest\\weather_id_RF.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REALIZAR LAS PREDICCIONES\n",
    "\n",
    "Usando los valores de los targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "df_predictions = pd.read_csv(r'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\predictions\\predictions_Prophet.csv')\n",
    "df_predictions.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df_predictions_copy = df_predictions.copy()\n",
    "\n",
    "df_predictions_copy['date'] = pd.to_datetime(df_predictions_copy['date'])\n",
    "df_predictions_copy['year'] = df_predictions_copy['date'].dt.year\n",
    "df_predictions_copy['month'] = df_predictions_copy['date'].dt.month\n",
    "df_predictions_copy['day'] = df_predictions_copy['date'].dt.day\n",
    "df_predictions_copy.drop('date', axis=1, inplace=True)\n",
    "\n",
    "model = joblib.load(r'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Entregables\\Code\\RandomForest\\weather_id_RF.pkl')\n",
    "\n",
    "predictions = model.predict(df_predictions_copy)\n",
    "\n",
    "df_predictions['weather_id'] = predictions\n",
    "\n",
    "df_predictions.to_csv(r'D:\\STUCOM\\Master_IABD\\Projecte3_Meteorologia\\Datos_Proyecto\\predictions\\predictions_Prophet_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZACION DE PREDICCIONES VS VALORES REALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graficar las predicciones vs los valores reales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)  # Línea de igualdad\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Valores Reales vs Predicciones')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, data[features], data[target], cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Cross-validation RMSE scores:\", np.sqrt(-scores))  # Convertir de negativo a positivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "target = 'precipitation'  # O el target de tu interés\n",
    "model = joblib.load(f'E:\\\\STUCOM\\\\Master_IABD\\\\Projecte3_Meteorologia\\\\Entregables\\\\Code\\\\RandomForest_Models\\\\{target}_model.pkl')\n",
    "\n",
    "# Crear un DataFrame con las fechas de interés\n",
    "fechas_interes = ['2025-01-10', '2025-01-11', '2025-01-12']  # Agrega las fechas para las que deseas predecir\n",
    "fechas_interes = pd.to_datetime(fechas_interes)\n",
    "\n",
    "# Crear las características correspondientes para las fechas de interés\n",
    "data_fechas = pd.DataFrame({\n",
    "    'date': fechas_interes,\n",
    "    'year': fechas_interes.year,\n",
    "    'month': fechas_interes.month,\n",
    "    'day': fechas_interes.day,\n",
    "    'precipitation': [0] * len(fechas_interes),  # La precipitación no importa en este caso\n",
    "    'temp_max': [0] * len(fechas_interes),  # O puedes poner valores estimados si los tienes\n",
    "    'temp_min': [0] * len(fechas_interes),  # Lo mismo para las otras variables\n",
    "    'wind': [0] * len(fechas_interes),\n",
    "    'humidity': [0] * len(fechas_interes),\n",
    "    'pressure': [0] * len(fechas_interes),\n",
    "    'solar_radiation': [0] * len(fechas_interes),\n",
    "    'visibility': [0] * len(fechas_interes),\n",
    "    'weather_id': [0] * len(fechas_interes),\n",
    "    'cloudiness_id': [0] * len(fechas_interes)\n",
    "})\n",
    "\n",
    "# Realizar las predicciones\n",
    "X_fechas_interes = data_fechas[features]  # Seleccionar las características\n",
    "predicciones = model.predict(X_fechas_interes)\n",
    "\n",
    "# Agregar las predicciones al DataFrame\n",
    "data_fechas['predicted_precipitation'] = predicciones\n",
    "\n",
    "# Mostrar las predicciones\n",
    "print(data_fechas[['date', 'predicted_precipitation']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
